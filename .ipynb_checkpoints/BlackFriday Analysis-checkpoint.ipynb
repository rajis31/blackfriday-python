{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import sqlite3 as sql\n",
    "import re\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"workflow.jpg?2\" width=\"750\" height=\"650\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above diagram, I outline the data science process in general. Ideally we start with **Step 0** which is identifying and framing a business decision problem. From here I'll define the rest of the steps \n",
    "\n",
    " **1. Data is Collected** - Here we identify the data elements that should be collected to solve the business problem. Here we also consider the amount of time to collect the data, how much data is needed to make your experiment impactful, costs, benefits vs. cons. We should identify all the needed data before moving on, and have a good understanding of the different data sources involved. \n",
    " \n",
    " **2. Data is Processed** - Here we prepare the data and get into a format that can be used for further analysis. This step normally takes the longest as the data source(s) maybe in different formats. For example, you may have data from a legacy system stored in 20 different tables while you have data coming from a non-relational database.\n",
    " \n",
    " **3. Clear the Data Set** - This is where we start to identify missing values, duplicates, outliers, and other things that would affect the data quality. Just note that we should simply not delete the data without doing further research as that data may contain some value information. \n",
    " \n",
    " **4. EDA** - This is also called exploratory data analysis. Here we create different plots and summarizations to identify patterns within the data. Just note if there are futher issues identified within the data then we go back to **step 2**.\n",
    "\n",
    " **5. Model Building** - This step we fit appropriate models based on business problem and it is experimental meaning that there is no right way to go about this. While there are clear things you should not do such as introduucing selection bias into your sample, no single model is correct. Just remember that all models are bad but there some better then others. \n",
    " \n",
    " **6. Communicate, Visualize, Report Building** - Here we formulate our analysis from the prior steps into something that is presentable and is clear. It should be straight to the point while taking the audience into heavy consideration. Your analysis will be used to help drive a business decision.\n",
    " \n",
    "I will be using this as a template for the rest of my analysis below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using **Black Friday** dataset from Kaggle and the link is  <a href=\"https://www.kaggle.com/mehdidag/black-friday\"> here </a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
